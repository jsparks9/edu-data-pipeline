{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3e10e4",
   "metadata": {},
   "source": [
    "# Analysis by LEA Sums\n",
    "In this notebook, about 7,800 districts are analysed. The data includes the total student enrollment in various programs and high school level courses. Districts with low enrollment are removed from the analysis. The analysis consists of principal component analysis (PCA), K-Means clustering, linear discriminant analysis (LDA), correlation, covariance, and multiple regression predicting poverty rate based on enrollment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "SELECT \n",
    "\trls.leaid\n",
    "\t,min(rls.lea_name) AS lea_name\n",
    "\t,min(rls.lea_state) as lea_state\n",
    "\t,sum(GREATEST(advmath.tot_mathenr_advm_m,0) + GREATEST(advmath.tot_mathenr_advm_f,0)) AS advmath_enr\n",
    "\t,sum(GREATEST(advpl.TOT_APEXAM_NONE_M,0) + GREATEST(advpl.TOT_APEXAM_NONE_F,0)) AS advpl_noexam\n",
    "\t,sum(GREATEST(alg1.TOT_ALGPASS_GS0910_M,0) + GREATEST(alg1.TOT_ALGPASS_GS0910_F,0)) AS alg1_0910_passed\n",
    "\t,sum(GREATEST(alg1.TOT_ALGPASS_GS1112_M,0) + GREATEST(alg1.TOT_ALGPASS_GS1112_F,0)) AS alg1_1112_passed\n",
    "\t,sum(GREATEST(alg2.tot_mathenr_alg2_m,0) + GREATEST(alg2.tot_mathenr_alg2_f,0)) AS alg2_enr\n",
    "\t,sum(GREATEST(bio.TOT_SCIENR_BIOL_M,0) + GREATEST(bio.TOT_SCIENR_BIOL_F,0)) AS bio_enr\n",
    "\t,sum(GREATEST(calc.TOT_MATHENR_CALC_M,0) + GREATEST(calc.TOT_MATHENR_CALC_F,0)) AS calc_enr\n",
    "\t,sum(GREATEST(chem.TOT_SCIENR_CHEM_M,0) + GREATEST(chem.TOT_SCIENR_CHEM_F,0)) AS chem_enr\n",
    "\t,sum(GREATEST(dual.TOT_DUAL_M,0) + GREATEST(dual.TOT_DUAL_F,0)) AS dual_enr\n",
    "\t,sum(GREATEST(enr.tot_enr_m,0) + GREATEST(enr.tot_enr_f,0)) AS total_enr\n",
    "\t,sum(GREATEST(enr.SCH_ENR_LEP_M,0) + GREATEST(enr.SCH_ENR_LEP_F,0)) AS enr_lep\n",
    "\t,sum(GREATEST(enr.SCH_ENR_504_M,0) + GREATEST(enr.SCH_ENR_504_F,0)) AS enr_504\n",
    "\t,sum(GREATEST(enr.SCH_ENR_IDEA_M,0) + GREATEST(enr.SCH_ENR_IDEA_F,0)) AS enr_idea\n",
    "\t,sum(GREATEST(geo.TOT_MATHENR_GEOM_M,0) + GREATEST(geo.TOT_MATHENR_GEOM_F,0)) AS geo_enr\n",
    "\t,sum(GREATEST(phys.TOT_SCIENR_PHYS_M,0) + GREATEST(phys.TOT_SCIENR_PHYS_F,0)) AS phys_enr\n",
    "\t,sum(GREATEST(satact.TOT_SATACT_M,0) + GREATEST(satact.TOT_SATACT_F,0)) AS satact\n",
    "\t,avg(saipe.totalpopulation) AS totalpopulation \n",
    "\t,avg(saipe.population5_17) AS population5_17\n",
    "\t,avg(saipe.population5_17inpoverty) AS population5_17inpoverty\n",
    "FROM ref_schema.ref_lea_sch rls\n",
    "JOIN data_schema.sch_advancedmathematics advmath ON advmath.combokey = rls.combokey\n",
    "JOIN data_schema.sch_advancedplacement advpl ON advpl.combokey = rls.combokey\n",
    "JOIN data_schema.sch_algebrai alg1 ON alg1.combokey = rls.combokey\n",
    "JOIN data_schema.sch_algebraii alg2 ON alg2.combokey = rls.combokey \n",
    "JOIN data_schema.sch_biology bio ON bio.combokey = rls.combokey \n",
    "JOIN data_schema.sch_calculus calc ON calc.combokey = rls.combokey \n",
    "JOIN data_schema.sch_chemistry chem ON chem.combokey = rls.combokey \n",
    "JOIN data_schema.sch_dualenrollment dual ON dual.combokey = rls.combokey \n",
    "JOIN data_schema.sch_enrollment enr ON enr.combokey = rls.combokey \n",
    "JOIN data_schema.sch_geometry geo ON geo.combokey = rls.combokey \n",
    "JOIN data_schema.sch_physics phys ON phys.combokey = rls.combokey \n",
    "JOIN data_schema.sch_satandact satact ON satact.combokey = rls.combokey \n",
    "JOIN data_schema.sch_schoolcharacteristics chr ON chr.combokey = rls.combokey \n",
    "JOIN data_schema.saipe_ussd17 saipe ON saipe.leaid = rls.leaid\n",
    "WHERE chr.hs_only = TRUE\n",
    "group by rls.leaid\n",
    "order by leaid;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "db_params = {\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"pwd123\",\n",
    "    \"host\": \"postgres-db\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "connection_string = f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from kneed import KneeLocator\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('LEA_agg_data_sums.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['leaid', 'lea_name', 'lea_state', \n",
    "                'totalpopulation', 'population5_17',\n",
    "                'population5_17inpoverty', 'total_enr']\n",
    "columns_to_modify = df.columns.difference(exclude_cols)\n",
    "df[columns_to_modify] = df[columns_to_modify].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_sum = df['total_enr']\n",
    "columns_to_modify = df.columns.difference(exclude_cols)\n",
    "df[columns_to_modify] = df[columns_to_modify].div(enrollment_sum, axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1226eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[enrollment_sum <= 10][['total_enr','leaid',\n",
    "                         'lea_state','totalpopulation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[enrollment_sum > 10]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57920e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5_17_poverty_percent'] = df['population5_17inpoverty']/df['population5_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.difference(exclude_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041cfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78104bb",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c489ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df['leaid'].values\n",
    "lea_names = df['lea_name'].values\n",
    "states = df['lea_state'].values\n",
    "pop5_17 = df['population5_17']\n",
    "pov5_17 = df['5_17_poverty_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df['leaid'].values\n",
    "\n",
    "# Step 1: Subset the DataFrame\n",
    "subset_df = df[df.columns.difference(exclude_cols)]\n",
    "for_pca_use = df[df['total_enr'] > 15][df.columns.difference(exclude_cols)]\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(subset_df)\n",
    "pca_data = scaler.fit_transform(for_pca_use)\n",
    "\n",
    "# Step 3: Compute covariance matrix, eigenvectors, and eigenvalues for PCA\n",
    "cov_matrix = np.cov(pca_data, rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvectors by eigenvalue size (descending order)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "# Step 4: Project data onto the top 3 principal components\n",
    "projected_data = np.dot(pca_data, eigenvectors[:, :3])\n",
    "\n",
    "# Step 5: Create an interactive 3D plot using Plotly\n",
    "trace = go.Scatter3d(\n",
    "    x=projected_data[:, 0],\n",
    "    y=projected_data[:, 1],\n",
    "    z=projected_data[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='blue', opacity=0.5),\n",
    "    text=[f\"LEA ID: {i}, {state}<br>LEA Name: {lea}<br>5_17 Pop: {int(pop)}<br>5_17 Pov: {100*pov:.2f}%\" \n",
    "          for i, lea, state, pop, pov in zip(ids, lea_names, states, pop5_17, pov5_17)],  \n",
    "    # Display ID, School Name, and LEA Name when hovering\n",
    "    hoverinfo=\"text+x+y+z\"\n",
    ")\n",
    "\n",
    "PC1_range = [projected_data[:, 0].min(),projected_data[:, 0].max()]\n",
    "PC2_range = [projected_data[:, 1].min(),projected_data[:, 1].max()]\n",
    "PC3_range = [projected_data[:, 2].min(),projected_data[:, 2].max()]\n",
    "for i in range(1,4):\n",
    "    exec(f\"extension = 0.1*(PC{i}_range[1] - PC{i}_range[0])\")\n",
    "    exec(f\"PC{i}_range[0] -= extension\")\n",
    "    exec(f\"PC{i}_range[1] += extension\")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Data Projected on Top 3 Principal Components\",\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title=\"Principal Component 1\",\n",
    "            range=[projected_data[:, 0].min(), projected_data[:, 0].max()]  \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Principal Component 2\"\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title=\"Principal Component 3\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9960d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_PC1 = df.iloc[np.argsort(np.abs(projected_data[:, 0]))[-3:]]\n",
    "extreme_PC1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = eigenvectors[:, 0]\n",
    "pc2 = eigenvectors[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d56091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.difference(exclude_cols)\n",
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(pc1)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*pc1[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34132f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC2 Weight\")\n",
    "for i in range(len(pc2)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*pc2[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(standardized_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_range, inertia, 'bo-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a204e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knee = KneeLocator(k_range, inertia, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "# Elbow point\n",
    "optimal_k = knee.elbow\n",
    "\n",
    "print(f\"The optimal number of clusters (k) is: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_cols = []\n",
    "unique_clusters = np.unique(df['cluster'])\n",
    "print(f\"{'Cluster'.ljust(10)}: LEAs in Dataset\")\n",
    "for cluster in unique_clusters:\n",
    "    count = np.sum(df['cluster'] == cluster)\n",
    "    print(f\"{str(cluster).ljust(10)}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2077946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(X, y):\n",
    "    mean = X.mean(axis=0)\n",
    "    class_labels = np.unique(y)\n",
    "    m, x_m, n = [[],[],[]]\n",
    "    for cl in class_labels:\n",
    "        data = X[y == cl]\n",
    "        m.append(data.mean(axis=0))\n",
    "        x_m.append(data - m[-1])\n",
    "        n.append(len(data))\n",
    "    Sw = sum((xm.T @ xm) for xm in x_m)\n",
    "    Sb = sum((np.outer(d,d)*n_i) for d, n_i in zip(m-mean,n))\n",
    "    eigval,eigvec=np.linalg.eig(np.linalg.inv(Sw)@Sb)\n",
    "    idx = np.argsort(eigval)[::-1]\n",
    "    return eigval[idx],np.real(eigvec[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardized_data\n",
    "y = df['cluster']\n",
    "eigval,eigvec = lda(X, y)\n",
    "X_lda = X@eigvec\n",
    "\n",
    "# Ensure that X_lda has at least 3 components for 3D plotting\n",
    "if X_lda.shape[1] < 3:\n",
    "    # Pad with zeros if fewer than 3 components\n",
    "    X_lda = np.pad(X_lda, ((0, 0), (0, 3 - X_lda.shape[1])), mode='constant')\n",
    "\n",
    "# Create an interactive 3D plot using Plotly\n",
    "trace = go.Scatter3d(\n",
    "    x=X_lda[:, 0],\n",
    "    y=X_lda[:, 1],\n",
    "    z=X_lda[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=y, opacity=0.8),\n",
    "    text=[f\"LEA ID: {i}, {state}<br>LEA Name: {lea}<br>5_17 Pop: {int(pop)}<br>5_17 Pov: {100*pov:.2f}%\" \n",
    "          for i, lea, state, pop, pov in zip(ids, lea_names, states, pop5_17, pov5_17)],  \n",
    "    # Display ID, School Name, and LEA Name when hovering\n",
    "    hoverinfo=\"text+x+y+z\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"LDA Projection on Top 3 Discriminant Components\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"LDA Component 1\",\n",
    "        yaxis_title=\"LDA Component 2\",\n",
    "        zaxis_title=\"LDA Component 3\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_LDA = df.iloc[np.argsort(np.abs(X_lda[:, 0]))[-3:]]\n",
    "extreme_LDA.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b00d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig1, eig2, eig3 =(eigvec.T)[:3] # column = eigvec\n",
    "exclude_cols.append('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(eig1)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*eig1[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(eig2)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*eig2[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edf4c4",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d83f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_df = pd.DataFrame(standardized_data)\n",
    "standardized_df.columns = df.columns.difference(exclude_cols)\n",
    "correlation_matrix = standardized_df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, fmt=\".2f\", cmap=\"bwr\", cbar=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96375f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = df[df.columns.difference(exclude_cols)].cov()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(covariance_matrix, annot=False, fmt=\".2f\", cmap=\"bwr\", cbar=True)\n",
    "plt.title('Covariance Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56aa6d5",
   "metadata": {},
   "source": [
    "## Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_var = '5_17_poverty_percent'\n",
    "independent_vars = df.columns.difference(exclude_cols + [dependent_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_p_vals = ['alg1_1112_passed','dual_enr','enr_idea']\n",
    "independent_vars = independent_vars.difference(high_p_vals)\n",
    "independent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eccbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[independent_vars]\n",
    "X = sm.add_constant(X)\n",
    "Y = df[dependent_var]\n",
    "model = sm.OLS(Y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fce921",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [vif(X.values, i) for i in range(X.shape[1])]\n",
    "vif_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
