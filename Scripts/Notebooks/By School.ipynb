{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3072ef2e",
   "metadata": {},
   "source": [
    "# Analysis by School\n",
    "In this notebook, the approximately 14k schools in the dataset are matched with the poverty percentage in each school's respective district. The data includes per-school enrollment of males and females in various programs and high school level courses. Schools with low enrollment are removed from the analysis. The analysis consists of principal component analysis (PCA), K-Means clustering, linear discriminant analysis (LDA), correlation, covariance, and multiple regression predicting poverty rate based on enrollment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1_query=\"\"\"\n",
    "SELECT \n",
    "\trls.leaid\n",
    "\t,rls.schid\n",
    "\t,rls.lea_name\n",
    "\t,rls.sch_name\n",
    "\t,rls.jj\n",
    "\t,advmath.tot_mathenr_advm_m AS advmath_m_enr\n",
    "\t,advmath.tot_mathenr_advm_f AS advmath_f_enr\n",
    "\t,advpl.TOT_APEXAM_NONE_M AS advpl_m_noexam\n",
    "\t,advpl.TOT_APEXAM_NONE_F AS advpl_f_noexam\n",
    "\t,alg1.TOT_ALGPASS_GS0910_M AS alg1_m_0910_passed\n",
    "\t,alg1.TOT_ALGPASS_GS1112_M AS alg1_m_1112_passed\n",
    "\t,alg1.TOT_ALGPASS_GS0910_F AS alg1_f_0910_passed\n",
    "\t,alg1.TOT_ALGPASS_GS1112_F AS alg1_f_1112_passed\n",
    "\t,alg2.tot_mathenr_alg2_m AS alg2_m_enr\n",
    "\t,alg2.tot_mathenr_alg2_f AS alg2_f_enr\n",
    "\t,bio.TOT_SCIENR_BIOL_M AS bio_m_enr\n",
    "\t,bio.TOT_SCIENR_BIOL_F AS bio_f_enr\n",
    "\t,calc.TOT_MATHENR_CALC_M AS calc_m_enr\n",
    "\t,calc.TOT_MATHENR_CALC_F AS calc_f_enr\n",
    "\t,chem.TOT_SCIENR_CHEM_M AS chem_m_enr\n",
    "\t,chem.TOT_SCIENR_CHEM_F AS chem_f_enr\n",
    "\t,dual.TOT_DUAL_M AS dual_m_enr\n",
    "\t,dual.TOT_DUAL_F AS dual_f_enr\n",
    "FROM ref_schema.ref_lea_sch rls\n",
    "JOIN data_schema.sch_advancedmathematics advmath ON advmath.combokey = rls.combokey\n",
    "JOIN data_schema.sch_advancedplacement advpl ON advpl.combokey = rls.combokey\n",
    "JOIN data_schema.sch_algebrai alg1 ON alg1.combokey = rls.combokey\n",
    "JOIN data_schema.sch_algebraii alg2 ON alg2.combokey = rls.combokey \n",
    "JOIN data_schema.sch_biology bio ON bio.combokey = rls.combokey \n",
    "JOIN data_schema.sch_calculus calc ON calc.combokey = rls.combokey \n",
    "JOIN data_schema.sch_chemistry chem ON chem.combokey = rls.combokey \n",
    "JOIN data_schema.sch_dualenrollment dual ON dual.combokey = rls.combokey \n",
    "JOIN data_schema.sch_schoolcharacteristics chr ON chr.combokey = rls.combokey \n",
    "JOIN data_schema.saipe_ussd17 saipe ON saipe.leaid = rls.leaid\n",
    "WHERE chr.hs_only = TRUE\n",
    "order by leaid;\n",
    "\"\"\"\n",
    "batch2_query=\"\"\"\n",
    "SELECT \n",
    "\trls.leaid\n",
    "\t,enr.tot_enr_m AS total_m_enr\n",
    "\t,enr.tot_enr_f AS total_f_enr\n",
    "\t,enr.SCH_ENR_LEP_M AS enr_lep_m\n",
    "\t,enr.SCH_ENR_LEP_F AS enr_lep_f\n",
    "\t,enr.SCH_ENR_504_M AS enr_504_m\n",
    "\t,enr.SCH_ENR_504_F AS enr_504_f\n",
    "\t,enr.SCH_ENR_IDEA_M AS enr_idea_m\n",
    "\t,enr.SCH_ENR_IDEA_F AS enr_idea_f\n",
    "\t,geo.TOT_MATHENR_GEOM_M AS geo_m_enr\n",
    "\t,geo.TOT_MATHENR_GEOM_F AS geo_f_enr\n",
    "\t,phys.TOT_SCIENR_PHYS_M AS phys_m_enr\n",
    "\t,phys.TOT_SCIENR_PHYS_F AS phys_f_enr\n",
    "\t,satact.TOT_SATACT_M AS satact_m\n",
    "\t,satact.TOT_SATACT_F AS satact_f\n",
    "\t,rls.lea_state\n",
    "\t,saipe.totalpopulation\n",
    "\t,saipe.population5_17\n",
    "\t,saipe.population5_17inpoverty\n",
    "FROM ref_schema.ref_lea_sch rls\n",
    "JOIN data_schema.sch_enrollment enr ON enr.combokey = rls.combokey \n",
    "JOIN data_schema.sch_geometry geo ON geo.combokey = rls.combokey \n",
    "JOIN data_schema.sch_physics phys ON phys.combokey = rls.combokey \n",
    "JOIN data_schema.sch_satandact satact ON satact.combokey = rls.combokey \n",
    "JOIN data_schema.sch_schoolcharacteristics chr ON chr.combokey = rls.combokey \n",
    "JOIN data_schema.saipe_ussd17 saipe ON saipe.leaid = rls.leaid\n",
    "WHERE chr.hs_only = TRUE\n",
    "order by leaid;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "db_params = {\n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"pwd123\",\n",
    "    \"host\": \"postgres-db\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "connection_string = f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dce3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from kneed import KneeLocator\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(batch1_query, engine)\n",
    "b2 = pd.read_sql(batch2_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bab5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('batch1.csv')\n",
    "# b2 = pd.read_csv('batch2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e907612",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in b2.columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = b2[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4314b95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21783db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['leaid', 'schid', 'lea_name', 'sch_name', 'jj', \n",
    "                'lea_state', 'totalpopulation', 'population5_17',\n",
    "                'population5_17inpoverty']\n",
    "columns_to_modify = df.columns.difference(exclude_cols)\n",
    "df[columns_to_modify] = df[columns_to_modify].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb922f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['leaid', 'schid', 'lea_name', 'sch_name', 'jj', \n",
    "                'lea_state', 'totalpopulation', 'population5_17',\n",
    "                'population5_17inpoverty', 'total_enrollment']\n",
    "enrollment_sum = df['total_m_enr'] + df['total_f_enr']\n",
    "df['total_enrollment'] = enrollment_sum\n",
    "columns_to_modify = df.columns.difference(exclude_cols)\n",
    "df[columns_to_modify] = df[columns_to_modify].div(enrollment_sum, axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ace28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[enrollment_sum <= 1][['total_enrollment','leaid',\n",
    "                         'sch_name','lea_state','totalpopulation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[enrollment_sum > 12]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5_17_poverty_percent'] = df['population5_17inpoverty']/df['population5_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.difference(exclude_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28283bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df['leaid'].values\n",
    "sch_names = df['sch_name'].values\n",
    "lea_names = df['lea_name'].values\n",
    "states = df['lea_state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3eb91b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = df['leaid'].values\n",
    "\n",
    "# Step 1: Subset the DataFrame\n",
    "subset_df = df[df.columns.difference(exclude_cols)]\n",
    "for_pca_use = df[df['total_enrollment'] > 15][df.columns.difference(exclude_cols)]\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(subset_df)\n",
    "pca_data = scaler.fit_transform(for_pca_use)\n",
    "\n",
    "# Step 3: Compute covariance matrix, eigenvectors, and eigenvalues for PCA\n",
    "cov_matrix = np.cov(pca_data, rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvectors by eigenvalue size (descending order)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "# Step 4: Project data onto the top 3 principal components\n",
    "projected_data = np.dot(pca_data, eigenvectors[:, :3])\n",
    "\n",
    "# Step 5: Create an interactive 3D plot using Plotly\n",
    "trace = go.Scatter3d(\n",
    "    x=projected_data[:, 0],\n",
    "    y=projected_data[:, 1],\n",
    "    z=projected_data[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='blue', opacity=0.8),\n",
    "    text=[f\"LEA ID: {i}, {state}<br>School Name: {sch}<br>LEA Name: {lea}\" \n",
    "          for i, sch, lea, state in zip(ids, sch_names, lea_names, states)],  \n",
    "    # Display ID, School Name, and LEA Name when hovering\n",
    "    hoverinfo=\"text+x+y+z\"\n",
    ")\n",
    "\n",
    "PC1_range = [projected_data[:, 0].min(),projected_data[:, 0].max()]\n",
    "PC2_range = [projected_data[:, 1].min(),projected_data[:, 1].max()]\n",
    "PC3_range = [projected_data[:, 2].min(),projected_data[:, 2].max()]\n",
    "for i in range(1,4):\n",
    "    exec(f\"extension = 0.1*(PC{i}_range[1] - PC{i}_range[0])\")\n",
    "    exec(f\"PC{i}_range[0] -= extension\")\n",
    "    exec(f\"PC{i}_range[1] += extension\")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Data Projected on Top 3 Principal Components\",\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title=\"Principal Component 1\",\n",
    "            range=[projected_data[:, 0].min(), projected_data[:, 0].max()]  \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Principal Component 2\"\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title=\"Principal Component 3\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_PC1 = df.iloc[np.argsort(np.abs(projected_data[:, 0]))[-3:]]\n",
    "extreme_PC1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84437a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = eigenvectors[:, 0]\n",
    "pc2 = eigenvectors[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.difference(exclude_cols)\n",
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(pc1)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*pc1[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC2 Weight\")\n",
    "for i in range(len(pc2)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*pc2[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7743e",
   "metadata": {},
   "source": [
    "### Comments\n",
    "PC1 has significant % for STEM enrollment while PC2 shows significantly negative % for physics, SAT/ACT, and 504 while high % for poverty, IDEA, and LEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b371fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(standardized_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_range, inertia, 'bo-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "knee = KneeLocator(k_range, inertia, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "# Elbow point\n",
    "optimal_k = knee.elbow\n",
    "\n",
    "print(f\"The optimal number of clusters (k) is: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0370b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a6e20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "enr_cols = []\n",
    "unique_clusters = np.unique(df['cluster'])\n",
    "print(f\"{'Cluster'.ljust(10)}: Schools in Dataset\")\n",
    "for cluster in unique_clusters:\n",
    "    count = np.sum(df['cluster'] == cluster)\n",
    "    print(f\"{str(cluster).ljust(10)}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25119fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(X, y):\n",
    "    mean = X.mean(axis=0)\n",
    "    class_labels = np.unique(y)\n",
    "    m, x_m, n = [[],[],[]]\n",
    "    for cl in class_labels:\n",
    "        data = X[y == cl]\n",
    "        m.append(data.mean(axis=0))\n",
    "        x_m.append(data - m[-1])\n",
    "        n.append(len(data))\n",
    "    Sw = sum((xm.T @ xm) for xm in x_m)\n",
    "    Sb = sum((np.outer(d,d)*n_i) for d, n_i in zip(m-mean,n))\n",
    "    eigval,eigvec=np.linalg.eig(np.linalg.inv(Sw)@Sb)\n",
    "    idx = np.argsort(eigval)[::-1]\n",
    "    return eigval[idx],np.real(eigvec[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e807f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardized_data\n",
    "y = df['cluster']\n",
    "eigval,eigvec = lda(X, y)\n",
    "X_lda = X@eigvec\n",
    "\n",
    "if X_lda.shape[1] < 3: # Pad with 0s if dim < 3\n",
    "    X_lda = np.pad(X_lda, ((0, 0), (0, 3 - X_lda.shape[1])), mode='constant')\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=X_lda[:, 0],\n",
    "    y=X_lda[:, 1],\n",
    "    z=X_lda[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=y, opacity=0.8),\n",
    "    text=[f\"LEA ID: {i}, {state}<br>School Name: {sch}<br>LEA Name: {lea}\" \n",
    "          for i, sch, lea, state in zip(ids, sch_names, lea_names, states)],  \n",
    "    # Display ID, School Name, and LEA Name when hovering\n",
    "    hoverinfo=\"text+x+y+z\"\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"LDA Projection on Top 3 Discriminant Components\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"LDA Component 1\",\n",
    "        yaxis_title=\"LDA Component 2\",\n",
    "        zaxis_title=\"LDA Component 3\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_LDA = df.iloc[np.argsort(np.abs(X_lda[:, 0]))[-3:]]\n",
    "extreme_LDA.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80646c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig1, eig2 =(eigvec.T)[:2] # column = eigvec\n",
    "exclude_cols.append('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(eig1)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*eig1[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63584b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column Name'.ljust(20)}: PC1 Weight\")\n",
    "for i in range(len(eig2)):\n",
    "    col_name = df.columns.difference(exclude_cols)[i]\n",
    "    print(f\"{col_name.ljust(20)}: {100*eig2[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de20be1",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1688b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_df = pd.DataFrame(standardized_data)\n",
    "standardized_df.columns = df.columns.difference(exclude_cols)\n",
    "correlation_matrix = standardized_df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b98c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, fmt=\".2f\", cmap=\"bwr\", cbar=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = df[df.columns.difference(exclude_cols)].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af844bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(covariance_matrix, annot=False, fmt=\".2f\", cmap=\"bwr\", cbar=True)\n",
    "plt.title('Covariance Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad5c17",
   "metadata": {},
   "source": [
    "## Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c62474",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_var = '5_17_poverty_percent'\n",
    "independent_vars = df.columns.difference(exclude_cols + [dependent_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_p_vals = ['advmath_f_enr','alg1_f_1112_passed','total_m_enr',\n",
    "               'advpl_m_noexam','chem_f_enr','alg2_m_enr','enr_lep_f',\n",
    "               'chem_m_enr','alg1_f_0910_passed','alg1_m_0910_passed',\n",
    "               'bio_m_enr','bio_f_enr', 'advpl_f_noexam']\n",
    "high_vif = ['calc_m_enr','dual_m_enr']\n",
    "independent_vars = independent_vars.difference(high_p_vals).difference(high_vif)\n",
    "independent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09542d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[independent_vars]\n",
    "X = sm.add_constant(X)\n",
    "Y = df[dependent_var]\n",
    "model = sm.OLS(Y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [vif(X.values, i) for i in range(X.shape[1])]\n",
    "vif_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
